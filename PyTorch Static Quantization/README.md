
# PyTorch Static Quantization


## Model Result
- FP32 evaluation accuracy: 0.869
- INT8 evaluation accuracy: 0.868
- FP32 CPU Inference Latency: 4.68 ms / sample
- FP32 CUDA Inference Latency: 3.70 ms / sample
- INT8 CPU Inference Latency: 2.03 ms / sample
- INT8 JIT CPU Inference Latency: 0.45 ms / sample